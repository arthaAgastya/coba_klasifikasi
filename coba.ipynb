{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coba.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hss36H0WrBuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications import InceptionV3\n",
        "from keras.applications import Xception # TensorFlow ONLY\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import VGG19\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToznAGcJrfC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a dictionary that maps model names to their classes\n",
        "# inside Keras\n",
        "MODELS = {\n",
        "\t\"vgg16\": VGG16,\n",
        "\t\"vgg19\": VGG19,\n",
        "\t\"inception\": InceptionV3,\n",
        "\t\"xception\": Xception, # TensorFlow ONLY\n",
        "\t\"resnet\": ResNet50\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrXEOHtWrHtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = \"vgg16\"\n",
        "#model = \"vgg19\"\n",
        "model = \"inception\"\n",
        "#model = \"xception\"\n",
        "#model = \"resnet\"\n",
        "\n",
        "Network = MODELS[model] # model bisa diganti - ganti\n",
        "model = Network(weights=\"imagenet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO0BkaLpuR4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the input image shape (224x224 pixels) along with\n",
        "# the pre-processing function (this might need to be changed\n",
        "# based on which model we use to classify our image)\n",
        "inputShape = (224, 224)\n",
        "preprocess = imagenet_utils.preprocess_input\n",
        "\n",
        "# if we are using the InceptionV3 or Xception networks, then we\n",
        "# need to set the input shape to (299x299) [rather than (224x224)]\n",
        "# and use a different image processing function\n",
        "if model == \"inception\" or \"xception\":\n",
        "\tinputShape = (299, 299)\n",
        "\tpreprocess = preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N77zqr9xs4DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O panda.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_G75DIdsYr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the input image using the Keras helper utility while ensuring\n",
        "# the image is resized to `inputShape`, the required input dimensions\n",
        "# for the ImageNet pre-trained network\n",
        "print(\"[INFO] loading and pre-processing image...\")\n",
        "\n",
        "\n",
        "image = load_img(\"/content/panda.jpg\", target_size=inputShape) # disesuaikan dengan alamat file tersebut\n",
        "\n",
        "\n",
        "image = img_to_array(image)\n",
        " \n",
        "# our input image is now represented as a NumPy array of shape\n",
        "# (inputShape[0], inputShape[1], 3) however we need to expand the\n",
        "# dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
        "# so we can pass it through thenetwork\n",
        "image = np.expand_dims(image, axis=0)\n",
        " \n",
        "# pre-process the image using the appropriate function based on the\n",
        "# model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
        "image = preprocess(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntulk46RtVaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "85930172-3b5b-4137-efdb-c2d4ab789078"
      },
      "source": [
        "# classify the image\n",
        "\n",
        "preds = model.predict(image)\n",
        "P = imagenet_utils.decode_predictions(preds)\n",
        " \n",
        "# loop over the predictions and display the rank-5 predictions +\n",
        "# probabilities to our terminal\n",
        "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
        "\tprint(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. giant_panda: 96.28%\n",
            "2. lesser_panda: 0.16%\n",
            "3. space_shuttle: 0.06%\n",
            "4. soccer_ball: 0.05%\n",
            "5. brown_bear: 0.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAZzfHBYtdcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}